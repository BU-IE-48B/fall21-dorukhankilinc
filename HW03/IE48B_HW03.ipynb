{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5de75f5-01e1-49ac-9528-15994f82a5a1",
   "metadata": {},
   "source": [
    "# IE 48B Homework 03 - Dorukhan Kılınç 2017402093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3f8c5a-ab6d-4f1a-a707-b26c1182e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from tslearn.piecewise import PiecewiseAggregateApproximation\n",
    "import cvxpy as cp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23013bc9-7228-417d-9059-60a796344eb0",
   "metadata": {},
   "source": [
    "## Task: Comparison of NN Classifiers with Alternative Representations and Distance Measures\n",
    "\n",
    "The aim of this task is to compare alternative representations and distance measures for classification. To achieve this, 5 different data sets from [http://www.timeseriesclassification.com/](http://www.timeseriesclassification.com/) are taken and nn classifiers with 4 distance measures(manhattan, euclidean, chebyshev, and minkowski distance with p = 5) are applied to 3 different representations (raw, principle components, and piecewise aggregate approximation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1ac02-91b2-455f-84b3-ec5c1926e73a",
   "metadata": {},
   "source": [
    "### Preperation of the Functions\n",
    "\n",
    "Since we will build the models on 5 different data sets, to avoid excessive coding, it is reasonable to write functions to build the models at first. Code below will take the original train and test data and firstly build models using the representations and distance measures mentioned above. Then, each model will be evaluated based on their repeated cross-validation score. In this task, 10-fold cross-validation with 5 repeats is used. Finally, based on these cross-validation scores, for each representation, models with the best scores will be built to make predictions on the test data and their accuracy scores will be compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7b635d-9fbd-4c2d-a2f2-59af9a316c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get mean cross validation score for each model\n",
    "def cv(model, X, y):\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "    scores = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "    \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c838549a-6d20-4310-8c3d-1999a08bfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pca representations for train and test set.\n",
    "#selection of number of components to use is automatized such that\n",
    "#the minimum number of components that are able to explain 90% of the variance is chosen.  \n",
    "def PCA_representation(X_train, X_test):\n",
    "    pca = PCA()\n",
    "    components_train = pca.fit_transform(X_train)\n",
    "    n_components = None\n",
    "    for n_components in range(1,X_train.shape[1]):\n",
    "        if sum(pca.explained_variance_ratio_[:2]) > 90: break\n",
    "    components_train = components_train[:, :n_components]\n",
    "    components_test = pca.transform(X_test)[:, :n_components]\n",
    "    return(components_train, components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58871ba2-4a43-442b-a104-4bacc484d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paa representation such that each segment represents 10 observations\n",
    "def PAA_representation(X_train, X_test):\n",
    "    n_paa_segments = int(X_train.shape[1] / 10)\n",
    "    paa = PiecewiseAggregateApproximation(n_segments=n_paa_segments)\n",
    "    shape_train = (len(X_train), n_paa_segments)\n",
    "    shape_test = (len(X_test), n_paa_segments)\n",
    "    return (paa.fit_transform(X_train).reshape(shape_train),\n",
    "            paa.fit_transform(X_test).reshape(shape_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e430a9-b355-491b-8403-c13c5b34c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply NN classifiers with k = 1,3,5 to each representation using the distance measures\n",
    "k_vals = [1, 3, 5]\n",
    "\n",
    "distance_measures = [\"manhattan\",\"euclidean\",\"chebyshev\", \"p = 5\"]\n",
    "\n",
    "def model_representation(X_rep, y):\n",
    "    scores = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        score = []\n",
    "        for measure in distance_measures:\n",
    "            model = None\n",
    "            if measure == \"p = 5\": model = KNeighborsClassifier(n_neighbors = k, p = 5)\n",
    "            else: model = KNeighborsClassifier(n_neighbors = k, metric = measure)\n",
    "            score.append(cv(model, X_rep, y))\n",
    "    \n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264bc211-1dbb-4ee4-9162-2db8b5455cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cv to select the best parameters and then make predicions on the test data\n",
    "representations = [\"raw\", \"paa\", \"pca\"]\n",
    "\n",
    "def print_results(X_train, y_train, X_test, y_test):\n",
    "    #representations for X_train and X_test\n",
    "    train, test = (None, None)\n",
    "    for representation in representations:\n",
    "        \n",
    "        if representation == \"raw\": \n",
    "            train, test = (X_train, X_test)\n",
    "        elif representation == \"paa\":\n",
    "            train, test = PAA_representation(X_train, X_test)\n",
    "        else: train, test = PCA_representation(X_train, X_test)\n",
    "        \n",
    "        #Calculate cv scores and find the best parameter set\n",
    "        scores = model_representation(train, y_train)\n",
    "        best_ind = np.unravel_index(np.argmax(scores, axis=None), scores.shape)\n",
    "        \n",
    "        best_k = best_ind[0]\n",
    "        best_k = k_vals[best_k]\n",
    "        \n",
    "        best_measure = best_ind[1]\n",
    "        best_measure = distance_measures[best_measure]\n",
    "        \n",
    "        #build the model using the best parameter set\n",
    "        model = None\n",
    "        if best_measure == \"p = 5\": model = KNeighborsClassifier(n_neighbors = best_k, p = 5)\n",
    "        else: model = KNeighborsClassifier(n_neighbors = best_k, metric = best_measure)  \n",
    "        \n",
    "        model.fit(train, y_train)\n",
    "        y_pred = model.predict(test)\n",
    "        \n",
    "        row = {\"representation\": representation, \"cv mean accuracy\": scores[best_ind],\n",
    "              \"best k parameter\": best_k, \"best distance measure\": best_measure,\n",
    "              \"test accuracy\": accuracy_score(y_test, y_pred)}\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcf1b7-6641-439f-b65c-115c7c6ca746",
   "metadata": {},
   "source": [
    "## Dataset 1: Earthquakes\n",
    "\n",
    "The earthquake classification problem involves predicting whether a major event is about to occur based on the most recent readings in the surrounding area. The data is taken from Northern California Earthquake Data Center and each data is an averaged reading for one hour, with the first reading taken on Dec 1st 1967, the last in 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6291df-1852-4469-8f52-3401fb6326ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data and prepare train and test matrices \n",
    "earthquakes_train = []\n",
    "for line in open(\"Earthquakes_TRAIN.txt\"):\n",
    "    earthquakes_train.append(line.split())\n",
    "\n",
    "earthquakes_train = np.array(earthquakes_train, dtype = \"float\")\n",
    "\n",
    "earthquakes_test = []\n",
    "for line in open(\"Earthquakes_TEST.txt\"):\n",
    "    earthquakes_test.append(line.split())\n",
    "\n",
    "earthquakes_test = np.array(earthquakes_test, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3eaf11-1dbe-4ae5-bac0-5cc925cfefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = earthquakes_train[:,1:]\n",
    "X1_test = earthquakes_test[:,1:]\n",
    "\n",
    "y1_train = earthquakes_train[:,0]\n",
    "y1_test = earthquakes_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de37813-893c-4d90-8940-f84eb0a93074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'representation': 'raw', 'cv mean accuracy': 0.796875, 'best k parameter': 5, 'best distance measure': 'euclidean', 'test accuracy': 0.7266187050359713}\n",
      "{'representation': 'paa', 'cv mean accuracy': 0.8043371212121212, 'best k parameter': 5, 'best distance measure': 'manhattan', 'test accuracy': 0.7410071942446043}\n",
      "{'representation': 'pca', 'cv mean accuracy': 0.8105871212121213, 'best k parameter': 5, 'best distance measure': 'manhattan', 'test accuracy': 0.7697841726618705}\n"
     ]
    }
   ],
   "source": [
    "print_results(X1_train, y1_train, X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa040c78-32bd-44d2-a4f2-cb36a407c672",
   "metadata": {},
   "source": [
    "Here above is the best model parameters for each representation and corresponding test accuracies. The best model is the last one with test accuracy near 0.77, with pca represenation, k = 5 and manhattan distance as the distance measure.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3edeb-eee3-4d06-804f-519b79148827",
   "metadata": {},
   "source": [
    "## Dataset 2: ECG200\n",
    "\n",
    "This dataset was formatted by R. Olszewski as part of his thesis “Generalized feature extraction for structural\tpattern recognition in time-series data,” at Carnegie Mellon University, 2001. Each series traces the electrical activity recorded during one\n",
    "heartbeat. The two classes are a normal heartbeat and a Myocardial Infarction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8bc506b-58a1-46d3-a72b-5e289cd5647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train = []\n",
    "for line in open(\"ECG200_TRAIN.txt\"):\n",
    "    ecg_train.append(line.split())\n",
    "\n",
    "ecg_train = np.array(ecg_train, dtype = \"float\")\n",
    "\n",
    "ecg_test = []\n",
    "for line in open(\"ECG200_TEST.txt\"):\n",
    "    ecg_test.append(line.split())\n",
    "\n",
    "ecg_test = np.array(ecg_test, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "560c5d79-c3ca-40ad-8038-2eaa8d503d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = ecg_train[:,1:]\n",
    "X2_test = ecg_test[:,1:]\n",
    "\n",
    "y2_train = ecg_train[:,0]\n",
    "y2_test = ecg_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b00f4fdc-ffc9-4e3d-8762-1c241bf6558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'representation': 'raw', 'cv mean accuracy': 0.91, 'best k parameter': 3, 'best distance measure': 'euclidean', 'test accuracy': 0.9}\n",
      "{'representation': 'paa', 'cv mean accuracy': 0.866, 'best k parameter': 1, 'best distance measure': 'p = 5', 'test accuracy': 0.87}\n",
      "{'representation': 'pca', 'cv mean accuracy': 0.91, 'best k parameter': 3, 'best distance measure': 'euclidean', 'test accuracy': 0.9}\n"
     ]
    }
   ],
   "source": [
    "print_results(X2_train, y2_train, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485040b-2683-44c7-a6cc-9d6c6586a55f",
   "metadata": {},
   "source": [
    "Here above are the best model parameters for each representation and corresponding test accuracies. In this case, there is a tie between raw and pca representations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164b380-9181-4eda-9ef1-f8916123175c",
   "metadata": {},
   "source": [
    "## Dataset 3: MixedShapesSmallTrain\n",
    "\n",
    "The data consist of \"pseudo\" time series obtained by converting two-dimensional shapes into one-dimensional time series from Wang, Xiaoyue, et al. \"Annotating historical archives of images.\" Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries. ACM, 2008 and Keogh, Eamonn, et al. \"LB_Keogh supports exact indexing of shapes under rotation invariance with arbitrary representations and distance measures.\" Proceedings of the 32nd international conference on Very large data bases. VLDB Endowment, 2006.\n",
    "\n",
    "There are five classes corresponding to different shapes.\n",
    "\n",
    "- Class 1: Arrowhead\n",
    "- Class 2: Butterfly\n",
    "- Class 3: Fish\n",
    "- Class 4: Seashell\n",
    "- Class 5: Shield\n",
    "\n",
    "There are two datasets out of these data. The two datasets share a same test set and only differ in the number of training instances. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d1025e-d202-4572-ac31-2202bd04b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_train = []\n",
    "for line in open(\"MixedShapesSmallTrain_TRAIN.txt\"):\n",
    "    shapes_train.append(line.split())\n",
    "\n",
    "shapes_train = np.array(shapes_train, dtype = \"float\")\n",
    "\n",
    "shapes_test = []\n",
    "for line in open(\"MixedShapesSmallTrain_TEST.txt\"):\n",
    "    shapes_test.append(line.split())\n",
    "\n",
    "shapes_test = np.array(shapes_test, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2514110-353e-4f86-a9eb-448519ff6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = shapes_train[:,1:]\n",
    "X3_test = shapes_test[:,1:]\n",
    "\n",
    "y3_train = shapes_train[:,0]\n",
    "y3_test = shapes_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddd3cf79-34f7-43fb-addd-2d2d0feb0833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'representation': 'raw', 'cv mean accuracy': 0.8460000000000002, 'best k parameter': 1, 'best distance measure': 'p = 5', 'test accuracy': 0.8255670103092784}\n",
      "{'representation': 'paa', 'cv mean accuracy': 0.8460000000000002, 'best k parameter': 1, 'best distance measure': 'p = 5', 'test accuracy': 0.8263917525773196}\n",
      "{'representation': 'pca', 'cv mean accuracy': 0.836, 'best k parameter': 1, 'best distance measure': 'euclidean', 'test accuracy': 0.8354639175257732}\n"
     ]
    }
   ],
   "source": [
    "print_results(X3_train, y3_train, X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cb6ba-9b27-44da-97c6-b6cdffb9f260",
   "metadata": {},
   "source": [
    "Here above are the best model parameters for each representation and corresponding test accuracies. In this case, the best one is the pca representation with k = 1 and euclidian metric as the distance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eace5-a3b1-4f8e-b183-3b49f7bedb06",
   "metadata": {},
   "source": [
    "## Dataset 4: Plane\n",
    "\n",
    "A data set of plane outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a07ae972-6d80-4ff2-99bf-ca9681bc0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_train = []\n",
    "for line in open(\"Plane_TRAIN.txt\"):\n",
    "    plane_train.append(line.split())\n",
    "\n",
    "plane_train = np.array(plane_train, dtype = \"float\")\n",
    "\n",
    "plane_test = []\n",
    "for line in open(\"Plane_TEST.txt\"):\n",
    "    plane_test.append(line.split())\n",
    "\n",
    "plane_test = np.array(plane_test, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07872e4b-43d3-4bc0-aaeb-67af59bc1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train = plane_train[:,1:]\n",
    "X4_test = plane_test[:,1:]\n",
    "\n",
    "y4_train = plane_train[:,0]\n",
    "y4_test = plane_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92d7aec5-3cf0-41d3-b02e-cc6cbd2279db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'representation': 'raw', 'cv mean accuracy': 0.9814545454545456, 'best k parameter': 3, 'best distance measure': 'manhattan', 'test accuracy': 0.9619047619047619}\n",
      "{'representation': 'paa', 'cv mean accuracy': 0.9740000000000001, 'best k parameter': 1, 'best distance measure': 'manhattan', 'test accuracy': 0.9619047619047619}\n",
      "{'representation': 'pca', 'cv mean accuracy': 0.9814545454545456, 'best k parameter': 3, 'best distance measure': 'euclidean', 'test accuracy': 0.9619047619047619}\n"
     ]
    }
   ],
   "source": [
    "print_results(X4_train, y4_train, X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234371bb-c6c5-448b-b22c-a1c10ca5f11a",
   "metadata": {},
   "source": [
    "Here above are the best model parameters for each representation and corresponding test accuracies. Notice that there is a tie between all the representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c141782-9de9-4c8e-8f00-51f07e00c08d",
   "metadata": {},
   "source": [
    "## Dataset 5: GunPointOldVersusYoung\n",
    "\n",
    "This dataset is a remake of the famous GunPoint dataset released in 2003. We strive to mimic in every aspect the recording of the original GunPoint. The actors include one male and one female. They are the same actors who created the original GunPoint.\n",
    "\n",
    "We record two scenarios, Gun and Point (also known as Gun and NoGun). In each scenario, the actors aim at a eye-level target. The difference between Gun and Point is that for the Gun scenario, the actors hold a gun, and in the Point scenario, the actors point with just their fingers. A complete Gun action involves the actor moves hand from an initial rest position, points the gun at target, puts gun back to waist holster and then brings free hand to the initial rest position. Each complete action conforms to a five-second cycle. With 30fps, this translates into 150 frames per action. We extract the centroid of the hand from each frame and use its x-axis coordinate to form a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03fafca1-db50-4010-b61a-d1b22ad7f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_train = []\n",
    "for line in open(\"GunPointOldVersusYoung_TRAIN.txt\"):\n",
    "    gun_train.append(line.split())\n",
    "\n",
    "gun_train = np.array(gun_train, dtype = \"float\")\n",
    "\n",
    "gun_test = []\n",
    "for line in open(\"GunPointOldVersusYoung_TEST.txt\"):\n",
    "    gun_test.append(line.split())\n",
    "\n",
    "gun_test = np.array(gun_test, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4599915b-2902-492a-aa4e-c6894d9e5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "X5_train = plane_train[:,1:]\n",
    "X5_test = plane_test[:,1:]\n",
    "\n",
    "y5_train = plane_train[:,0]\n",
    "y5_test = plane_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76534f83-7504-4422-8348-d99fb15e1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'representation': 'raw', 'cv mean accuracy': 0.9814545454545456, 'best k parameter': 3, 'best distance measure': 'manhattan', 'test accuracy': 0.9619047619047619}\n",
      "{'representation': 'paa', 'cv mean accuracy': 0.9740000000000001, 'best k parameter': 1, 'best distance measure': 'manhattan', 'test accuracy': 0.9619047619047619}\n",
      "{'representation': 'pca', 'cv mean accuracy': 0.9814545454545456, 'best k parameter': 3, 'best distance measure': 'euclidean', 'test accuracy': 0.9619047619047619}\n"
     ]
    }
   ],
   "source": [
    "print_results(X5_train, y5_train, X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb942e6f-78c9-4491-b2d0-2a3979ba3c66",
   "metadata": {},
   "source": [
    "Here above are the best model parameters for each representation and corresponding test accuracies. Notice that there is a tie between all the representations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
